{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_0925face_dataset_transfer_learning.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPocTY+G2pVNIWL98YQJvzE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/2015corona/blob/master/2021notebooks/2021_0925face_dataset_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e17NdrfUqK-p"
      },
      "source": [
        "# -*- coding: utf8 -*-"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLDLzOJyptSV"
      },
      "source": [
        "# 顔，非顔判別データセットを用いた紡錘状回のモデル化 --- 転移学習を用いた顔検出モデル ---\n",
        "\n",
        "- source: file:///Users/asakawa/study/2020pytorch_tutorials.git/beginner_source/transfer_learning_tutorial.py\n",
        "- data: 2021_1001\n",
        "- author: 浅川伸一\n",
        "- filename: 2021_0925face_transfer_leaning.ipynb\n",
        "- original author: [Sasank Chilamkurthy](https://chsasank.github.io)\n",
        "- License: BSD\n",
        "\n",
        "\n",
        "実際には， 十分なサイズのデータセットを持つことは比較的まれであるため， 最初から (ランダムな初期化を行って) 畳み込みニューラルネットワーク全体を学習する人はほとんどいない。その代わり， 非常に大規模なデータセット (例えば 120 万枚の画像と 1000 カテゴリの ImageNet) で ConvNet を事前学習し， その ConvNet を初期化または目的の課題のための固定の特徴抽出器として使用するのが一般的である。\n",
        "<!-- In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively     rare to have a dataset of sufficient size. \n",
        "    Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest.   -->\n",
        "\n",
        "この 2 つの主要な転送学習シナリオは次のようになります。\n",
        "\n",
        "- **畳み込みニューラルネットワークの初期化**  ランダムな初期化の代わりに imagenet 1000 データセットで学習されたような， 事前学習されたネットワークでネットワークを初期化する。\n",
        "- **詳細学習** その後の学習は通常通り\n",
        "- **転移学習** 最後の完全連結層を除いて，すべてのネットワークの重みを固定する。\n",
        "この最終完全連結層は，ランダムな重みを持つ新しい層に置き換えられ，この層だけが学習される。\n",
        "\n",
        "\n",
        "- 資料:\n",
        "転移学習については [cs231n notes](https://cs231n.github.io/transfer-learning/)で詳しく紹介されている。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lqyz2ezqu0M"
      },
      "source": [
        "# データの取得\n",
        "!wget https://komazawa-deep-learning.github.io/2021komazawa_faces.tgz -O 2021komazawa_faces.tgz\n",
        "!tar xzf 2021komazawa_faces.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "648YtQOXqsot"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "plt.ion()   # interactive mode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCtopGsPqV3O"
      },
      "source": [
        "# 訓練データに対しては，データ拡張と正規化を行い\n",
        "# 検証データに対しては，正規化を行う\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        #transforms.RandomResizedCrop(224),  # \n",
        "        transforms.RandomHorizontalFlip(),  # ランダムに左右反転\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = 'data'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "\n",
        "# GPU が利用可能かどうかを調べる\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# GPU が利用可能であれば n_worker=2 にし，そうでなければ 4 に設定\n",
        "n_worker = 4 if device == 'cpu' else 2\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
        "                                              batch_size=64,\n",
        "                                              shuffle=True, \n",
        "                                              num_workers=n_worker, \n",
        "                                              drop_last=True)\n",
        "              for x in ['train', 'val']}\n",
        "\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "print(f'class_names:{class_names}')\n",
        "print(f'dataset_sizes:{dataset_sizes}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEOcR49MzAlV"
      },
      "source": [
        "# 1. データの可視化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiWcAnqUzDaa"
      },
      "source": [
        "def imshow(inp, title=None, figsize=(10,10)):\n",
        "    \"\"\"テンソルを画像として表示\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes], figsize=(20,20))\n",
        "for i, v in enumerate(classes):\n",
        "    v_ja = '非顔' if v == 1 else '  顔'\n",
        "    print(v_ja, end=\" \")\n",
        "    if (i+1) % 8 == 0:\n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cYdCpAFzNWN"
      },
      "source": [
        "# 2. モデルの訓練\n",
        "\n",
        "モデルを訓練するための一般的な関数を定義\n",
        "\n",
        "- 学習率のスケジューリング\n",
        "- ベストモデルの保存\n",
        "\n",
        "以下では パラメータ ``scheduler`` に ``torch.optim.lr_scheduler`` の LR スケジューラオブジェクトを指定しています。\n",
        "<!-- Now, let's write a general function to train a model. \n",
        "Here, we will illustrate:\n",
        "\n",
        "-  Scheduling the learning rate\n",
        "-  Saving the best model\n",
        "\n",
        "In the following, parameter ``scheduler`` is an LR scheduler object from ``torch.optim.lr_scheduler``. -->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew8JNOnUzE-_"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "\n",
        "        # 各エポックごとに，訓練データを用いた学習と検証データを用いた検証を繰り返す\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # 訓練モード, PyTorch では学習時に設定\n",
        "            else:\n",
        "                model.eval()   # 評価モード，PyTorch では評価時に設定，学習は行われない\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # データセット中の全データを用いて繰り返し\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # 勾配の初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 前向き処理\n",
        "                # 訓練時は学習履歴を保存しておく\n",
        "                cnt = 0\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # 逆向き処理，学習時\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # 損失値の計算\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} 損失: {epoch_loss:.3f} 精度: {epoch_acc:.3f}')\n",
        "\n",
        "            # 性能が良ければ保存する\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'訓練終了 {time_elapsed // 60:.0f}分 {time_elapsed % 60:.0f}秒')\n",
        "    print(f'最良精度: {best_acc:4f}')\n",
        "\n",
        "    # 最良精度達成時のモデルを返す\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teydeagWzW_p"
      },
      "source": [
        "# 3. モデル予測の視覚化\n",
        "\n",
        "<!-- # Visualizing the model predictions --->\n",
        "<!--\n",
        "# Generic function to display predictions for a few images\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GKeihL9zUBI"
      },
      "source": [
        "def visualize_model(model, num_images=6, figsize=(6,6)):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j], figsize=figsize)\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7igwaTLAzd_k"
      },
      "source": [
        "# 3. 詳細チューニング\n",
        "\n",
        "<!-- # Finetuning the convnet\n",
        "# ----------------------\n",
        "#\n",
        "# Load a pretrained model and reset final fully connected layer.\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KL3yDrhzaRU"
      },
      "source": [
        "model_finetune = models.resnet18(pretrained=True)\n",
        "n_feature = model_finetune.fc.in_features\n",
        "# 最終層のニューロン数を 2 に付け替え\n",
        "# これは，顔 非顔の 2 分類にするために 2 としている。\n",
        "# 事前学習済のモデルは Imagenet の 1000 分類なので，最終層のニューロン数は 1000 になっている。\n",
        "# この 1000 個の出力層ニューロンは，一般画像認識のための出力層ニューロン数であるため，\n",
        "# 2 (顔，非顔) に置き換える\n",
        "model_finetune.fc = nn.Linear(n_feature, 2)\n",
        "model_finetune = model_finetune.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  # 交差エントロピー損失を評価関数とする\n",
        "\n",
        "# 最適化手法として，確率的勾配降下法 (Bottou, 2003) を用いる\n",
        "optimizer_finetune = optim.SGD(model_finetune.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 学習係数 LR を 7 エポック毎に減衰させる\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_finetune, step_size=1, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR34G5UJ2MLP"
      },
      "source": [
        "## 3.1 細密チューニングによる訓練と評価"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DUZkHiJzh0p"
      },
      "source": [
        "model_finetune = train_model(model_finetune, \n",
        "                             criterion, \n",
        "                             optimizer_finetune, \n",
        "                             exp_lr_scheduler,\n",
        "                             num_epochs=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahebj1Sx3qZN"
      },
      "source": [
        "## 3.2 細密チューニングによる学習結果の視覚化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWXHrq7uzmsz"
      },
      "source": [
        "visualize_model(model_finetune, figsize=(4,4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrwBvgSpz4-q"
      },
      "source": [
        "# 4. 転移学習による顔識別器の訓練\n",
        "\n",
        "\n",
        "ここでは， 最終層を除くすべてのネットワークを凍結させる必要があります。\n",
        "また  ``requires_grad == False``  を設定してパラメータを固定し，  ``backward()``  で勾配が計算されないようにする必要があります。\n",
        "\n",
        "これについての詳細は，以下の文書をご覧ください:\n",
        "<https://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward>\n",
        "\n",
        "<!-- Here, we need to freeze all the network except the final layer. \n",
        "We need to set ``requires_grad == False`` to freeze the parameters so that the gradients are not computed in ``backward()``.\n",
        "\n",
        "You can read more about this in the documentation \n",
        "`here <https://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward>`. -->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iqyt_Otzss-"
      },
      "source": [
        "model_transfer = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model_transfer.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 新しく追加したパラメータはあらかじめ，requires_grad=True すなわち学習可能な状態になっている\n",
        "n_feature = model_transfer.fc.in_features\n",
        "model_transfer.fc = nn.Linear(n_feature, 2)\n",
        "\n",
        "model_transfer = model_transfer.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_transfer = optim.SGD(model_transfer.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_transfer, step_size=7, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whgPGE8Pz92X"
      },
      "source": [
        "# 4.1 訓練と評価\n",
        "<!-- # Train and evaluate -->\n",
        "\n",
        "CPU では 先ほどのシナリオと比べて約半分の時間で済みます。\n",
        "これは， ネットワークのほとんどの部分で勾配を計算する必要がないことから予想されます。\n",
        "しかし，前向き計算は実行する必要があります。\n",
        "<!-- On CPU this will take about half the time compared to previous scenario.\n",
        "This is expected as gradients don't need to be computed for most of the network. \n",
        "However, forward does need to be computed.\n",
        " -->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szTRxZNUz_kE"
      },
      "source": [
        "model_transfer = train_model(model_transfer,\n",
        "                             criterion, \n",
        "                             optimizer_transfer,\n",
        "                             exp_lr_scheduler, \n",
        "                             num_epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N5R70P30B7q"
      },
      "source": [
        "visualize_model(model_transfer, figsize=(4,4))\n",
        "\n",
        "plt.ioff()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qd8y0YU0LRa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}