{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "2021cnps_ccap3_tSNE_distance_demo.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/2015corona/blob/master/notebooks/2021cnps_ccap3_tSNE_distance_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCd-RXCh96wZ"
      },
      "source": [
        "# TLPA 図版の単語を word2vec でベクトル化し tSNE で距離を求めるデモ\n",
        "\n",
        "- date: 2021_0830\n",
        "- filename: 2021cnps_ccap3_tSNE_distance.ipynb\n",
        "- author: 浅川伸一 <asakawa@ieee.org>\n",
        "- note: 2021cnps 配布用\n",
        "- License: MIT License\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHriyazEyHEc"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import numpy as np\n",
        "# 表示精度桁数の設定\n",
        "np.set_printoptions(suppress=False, formatter={'float': '{:6.3f}'.format})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz50bKNqi5zu"
      },
      "source": [
        "# 形態素分析ライブラリ MeCab と 辞書 mecab-ipadic-NEologd のインストール \n",
        "# reference: https://qiita.com/jun40vn/items/78e33e29dce3d50c2df1\n",
        "!apt-get -q -y install sudo file mecab libmecab-dev mecab-ipadic-utf8 git curl python-mecab\n",
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git\n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n\n",
        "!pip install mecab-python3\n",
        "\n",
        "# シンボリックリンクによるエラー回避\n",
        "!ln -s /etc/mecabrc /usr/local/etc/mecabrc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnDY6cIKjRus"
      },
      "source": [
        "# 動作確認\n",
        "import MeCab\n",
        "neologd_path = \"-d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\"\n",
        "m = MeCab.Tagger(neologd_path +' -Oyomi')\n",
        "print(m.parse('鬼滅の刃'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "typUIMFS0x3t"
      },
      "source": [
        "#訓練済 word2vec ファイルの取得\n",
        "#!wget --no-check-certificate --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1B9HGhLZOja4Xku5c_d-kMhCXn1LBZgDb' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1B9HGhLZOja4Xku5c_d-kMhCXn1LBZgDb\" -O 2021_05jawiki_hid128_win10_neg10_cbow.bin.gz && rm -rf /tmp/cookies.txt\n",
        "#!wget --no-check-certificate --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1OWmFOVRC6amCxsomcRwdA6ILAA5s4y4M' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1OWmFOVRC6amCxsomcRwdA6ILAA5s4y4M\" -O 2021_05jawiki_hid128_win10_neg10_sgns.bin.gz && rm -rf /tmp/cookies.txt\n",
        "#!wget --no-check-certificate --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1JTkU5SUBU2GkURCYeHkAWYs_Zlbqob0s' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1JTkU5SUBU2GkURCYeHkAWYs_Zlbqob0s\" -O 2021_05jawiki_hid200_win20_neg20_cbow.bin.gz && rm -rf /tmp/cookies.txt\n",
        "#!wget --no-check-certificate --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1VPL2Mr9JgWHik9HjRmcADoxXIdrQ3ds7' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1VPL2Mr9JgWHik9HjRmcADoxXIdrQ3ds7\" -O 2021_05jawiki_hid200_win20_neg20_sgns.bin.gz && rm -rf /tmp/cookies.txt\n",
        "\n",
        "#旧版の訓練済 word2vec データの取得\n",
        "!wget http://www.cis.twcu.ac.jp/~asakawa/2017jpa/2017Jul_jawiki-wakati_neologd_hid200_win20_neg20_cbow.bin.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6q-E4UPzKn_"
      },
      "source": [
        "#直上のセルで取得したファイルの読み込み\n",
        "#word2vec データ処理のため gensim を使う\n",
        "import os\n",
        "import sys\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "print('# word2vec データの読み込み')\n",
        "print('# 訓練済 word2vec，訓練データは wikipedia 全文  読み込みに時間がかかります...', end=\"\")\n",
        "# ファイルの所在に応じて変更してください\n",
        "w2v_base = '.'\n",
        "#w2v_file='2021_05jawiki_hid128_win10_neg10_cbow.bin.gz'\n",
        "#w2v_file='2021_05jawiki_hid128_win10_neg10_sgns.bin.gz'\n",
        "#w2v_file='2021_05jawiki_hid200_win20_neg20_cbow.bin.gz'\n",
        "w2v_file='2017Jul_jawiki-wakati_neologd_hid200_win20_neg20_cbow.bin.gz'\n",
        "#w2v_file='2021_05jawiki_hid200_win20_neg20_sgns.bin.gz'\n",
        "w2v_file = os.path.join(w2v_base, w2v_file)\n",
        "w2v = KeyedVectors.load_word2vec_format(w2v_file, \n",
        "                                        encoding='utf-8', \n",
        "                                        unicode_errors='replace',\n",
        "                                        binary=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIIPQInD9WmZ"
      },
      "source": [
        "# 散布図中に日本語を表示するための準備\n",
        "!pip install japanize_matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPdSNZrB5NjJ"
      },
      "source": [
        "# TLPA のデータ\n",
        "tlpa_labels = ['バス', '緑', '桜', 'のり巻き', '五重塔', 'コップ', 'ごぼう', '土踏まず', '風呂', 'ヒトデ', 'ハム', '兎', 'ロープウエイ', '学校', 'ちりとり', '縁側', '歯', 'ネギ', 'あじさい', '灰色', '天井', '鍵', '肌色', 'ワニ', '電車', '顔', '松', 'ガードレール', '柿', 'ちまき', '信号', 'すすき', 'じょうろ', 'コンセント', '天ぷら', '中指', 'ヨット', 'ピンク', 'ふくろう', 'みかん', '柱', '角砂糖', '犬', 'かご', 'バラ', '鍋', 'まぶた', 'くるみ', '黒', 'デパート', 'カーネーション', '城', '蟻', '豆腐', 'ドライバー', '紺', '階段', '戦車', '人参', '背中', '鏡餅', 'スプーン', '朝顔', '金', '足', 'ふすま', '蛇', 'レモン', '公園', '乳母車', '床', '藤', 'ピンセット', 'トラック', '苺', '黄土色', '銭湯', 'ナマズ', 'そば', 'お腹', 'オレンジ', 'バター', '工場', '鳩', '電卓', '喉仏', 'チューリップ', '白菜', 'トラクター', '廊下', 'パトカー', '押入れ', '鉛筆', '目尻', '芋', '吊り橋', '赤', 'かき氷', '豹', 'サボテン', 'ピラミッド', 'サイ', '目', 'ひまわり', 'はたき', '刺し身', '玄関', 'トマト', '黄緑', '三輪車', '鶏', 'つむじ', 'アスパラガス', 'ドア', '銀色', 'すりこ木', 'ウイスキー', '梅', 'タクシー', '動物園', '床の間', '焦げ茶', 'ぶどう', '飴', '毛虫', 'アイロン', '寺', 'そり', 'ひょうたん', '首', '消しゴム', '頬', 'いちょう', '駅', 'ギョウザ', '牛', 'びわ', '飛行機', '畳', '白', '竹', 'ペリカン', '紫', '手すり', '口', '大根', '風車', '鋏', '潜水艦', 'ステーキ', 'マッチ', '二階', '落花生', '御飯', '自転車', '歩道橋', '鯨', '茶色', '菖蒲', 'ふくらはぎ', '桃', 'たいやき', '道路', '靴べら', '水色', '壁', 'たんぽぽ', 'いかだ', '山羊', '鼻', '海老', '台所', 'オートバイ', 'かぶ', '柳', 'しゃもじ', 'まんじゅう', 'かかと', '薄紫', '家', 'おせち料理', '青', '傘', 'つくし', 'りんご', '馬車', '線路', 'タツノオトシゴ', '耳', '便所', '蓮根', '猫', '黄色', 'へそ', '街灯', '障子', '酒', '船', '安全ピン', 'もみじ']\n",
        "tlpa_fam = ['高', '高', '高', '低', '低', '高', '低', '低', '高', '低', '高', '高', '低', '高', '低', '低', '高', '高', '低', '低', '高', '高', '低', '低', '高', '高', '高', '低', '低', '低', '高', '低', '低', '低', '高', '低', '高', '高', '低', '高', '低', '低', '高', '低', '高', '高', '低', '低', '高', '高', '低', '低', '高', '高', '低', '低', '高', '低', '高', '高', '低', '高', '高', '低', '高', '低', '高', '低', '高', '低', '高', '低', '低', '高', '高', '低', '低', '低', '高', '高', '高', '高', '高', '高', '低', '低', '高', '低', '低', '低', '高', '高', '高', '低', '高', '低', '高', '低', '低', '低', '低', '低', '高', '高', '低', '高', '高', '高', '低', '低', '高', '低', '低', '高', '低', '低', '低', '高', '高', '高', '低', '低', '高', '高', '低', '高', '高', '低', '低', '高', '高', '低', '低', '高', '低', '高', '低', '高', '低', '高', '高', '低', '高', '低', '高', '高', '低', '高', '低', '低', '高', '低', '低', '高', '高', '低', '高', '高', '低', '低', '高', '低', '高', '低', '低', '高', '高', '低', '低', '高', '高', '高', '高', '低', '低', '低', '高', '低', '低', '高', '低', '高', '高', '低', '高', '低', '低', '低', '高', '高', '低', '高', '高', '低', '低', '低', '高', '高', '低', '高']\n",
        "tlpa_cat = ['乗り物', '色', '植物', '加工食品', '建造物', '道具', '野菜果物', '身体部位', '屋内部位', '動物', '加工食品', '動物', '乗り物', '建造物', '道具', '屋内部位', '身体部位', '野菜果物', '植物', '色', '屋内部位', '道具', '色', '動物', '乗り物', '身体部位', '植物', '建造物', '野菜果物', '加工食品', '建造物', '植物', '道具', '屋内部位', '加工食品', '身体部位', '乗り物', '色', '動物', '野菜果物', '屋内部位', '加工食品', '動物', '乗り物', '植物', '道具', '身体部位', '野菜果物', '色', '建造物', '植物', '建造物', '動物', '加工食品', '道具', '色', '屋内部位', '乗り物', '野菜果物', '身体部位', '加工食品', '道具', '植物', '色', '身体部位', '屋内部位', '動物', '野菜果物', '建造物', '乗り物', '屋内部位', '植物', '道具', '乗り物', '野菜果物', '色', '建造物', '動物', '加工食品', '身体部位', '色', '加工食品', '建造物', '動物', '道具', '身体部位', '植物', '野菜果物', '乗り物', '屋内部位', '乗り物', '屋内部位', '道具', '身体部位', '野菜果物', '建造物', '色', '加工食品', '動物', '植物', '建造物', '動物', '身体部位', '植物', '道具', '加工食品', '屋内部位', '野菜果物', '色', '乗り物', '動物', '身体部位', '野菜果物', '屋内部位', '色', '道具', '加工食品', '植物', '乗り物', '建造物', '屋内部位', '色', '野菜果物', '加工食品', '動物', '道具', '建造物', '乗り物', '植物', '身体部位', '道具', '身体部位', '植物', '建造物', '加工食品', '動物', '野菜果物', '乗り物', '屋内部位', '色', '植物', '動物', '色', '屋内部位', '身体部位', '野菜果物', '建造物', '道具', '乗り物', '加工食品', '道具', '屋内部位', '野菜果物', '加工食品', '乗り物', '建造物', '動物', '色', '植物', '身体部位', '野菜果物', '加工食品', '建造物', '道具', '色', '屋内部位', '植物', '乗り物', '動物', '身体部位', '動物', '屋内部位', '乗り物', '野菜果物', '植物', '道具', '加工食品', '身体部位', '色', '建造物', '加工食品', '色', '道具', '植物', '野菜果物', '乗り物', '建造物', '動物', '身体部位', '屋内部位', '野菜果物', '動物', '色', '身体部位', '建造物', '屋内部位', '加工食品', '乗り物', '道具', '植物']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwARuxBfLtdj"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "\"\"\"\n",
        "- source: https://lvdmaaten.github.io/tsne/\n",
        "- オリジナルの tSNE python 実装を python 3 系で呼び出せるように変更したバージョン\n",
        "- date: 2021_0510\n",
        "- author: 浅川伸一\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import tsne\n",
        "\n",
        "X = np.random.random(100, 30)\n",
        "result = tsne.tsne(X)\n",
        "```\n",
        "\"\"\"\n",
        "#  tsne.py\n",
        "#\n",
        "# Implementation of t-SNE in Python. The implementation was tested on Python 2.7.10, and it requires a working\n",
        "# installation of NumPy. The implementation comes with an example on the MNIST dataset. In order to plot the\n",
        "# results of this example, a working installation of matplotlib is required.\n",
        "#\n",
        "# The example can be run by executing: `ipython tsne.py`\n",
        "#\n",
        "#\n",
        "#  Created by Laurens van der Maaten on 20-12-08.\n",
        "#  Copyright (c) 2008 Tilburg University. All rights reserved.\n",
        "\n",
        "#import numpy as Math\n",
        "#import pylab as Plot\n",
        "\n",
        "def Hbeta(D = np.array([]), beta = 1.0):\n",
        "    \"\"\"Compute the perplexity and the P-row for a specific value of the precision of a Gaussian distribution.\"\"\"\n",
        "\n",
        "    # Compute P-row and corresponding perplexity\n",
        "    P = np.exp(-D.copy() * beta)\n",
        "    sumP = sum(P) if sum(P) > 1e-12 else 1e-12    # to avoid division by zero ここだけ加えた。直下行が division by zero error にならないように \n",
        "    H = np.log(sumP) + beta * np.sum(D * P) / sumP\n",
        "    P = P / sumP\n",
        "    return H, P\n",
        "\n",
        "\n",
        "def x2p(X = np.array([]), tol=1e-5, perplexity=30.0):\n",
        "    \"\"\"Performs a binary search to get P-values in such a way that each conditional Gaussian has the same perplexity.\"\"\"\n",
        "\n",
        "    # Initialize some variables\n",
        "    #print(\"Computing pairwise distances...\")\n",
        "    (n, d) = X.shape\n",
        "    sum_X = np.sum(np.square(X), 1)\n",
        "    D = np.add(np.add(-2 * np.dot(X, X.T), sum_X).T, sum_X)\n",
        "    P = np.zeros((n, n))\n",
        "    beta = np.ones((n, 1))\n",
        "    logU = np.log(perplexity)\n",
        "\n",
        "    # Loop over all datapoints\n",
        "    for i in range(n):\n",
        "\n",
        "        # Print progress\n",
        "        #if i % 500 == 0:\n",
        "        #    print(\"Computing P-values for point \", i, \" of \", n, \"...\")\n",
        "\n",
        "        # Compute the Gaussian kernel and entropy for the current precision\n",
        "        betamin = -np.inf\n",
        "        betamax =  np.inf\n",
        "        Di = D[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))]\n",
        "        (H, thisP) = Hbeta(Di, beta[i])\n",
        "\n",
        "        # Evaluate whether the perplexity is within tolerance\n",
        "        Hdiff = H - logU\n",
        "        tries = 0\n",
        "        while np.abs(Hdiff) > tol and tries < 50:\n",
        "\n",
        "            # If not, increase or decrease precision\n",
        "            if Hdiff > 0:\n",
        "                betamin = beta[i].copy()\n",
        "                if betamax == np.inf or betamax == -np.inf:\n",
        "                    beta[i] = beta[i] * 2\n",
        "                else:\n",
        "                    beta[i] = (beta[i] + betamax) / 2;\n",
        "            else:\n",
        "                betamax = beta[i].copy()\n",
        "                if betamin == np.inf or betamin == -np.inf:\n",
        "                    beta[i] = beta[i] / 2\n",
        "                else:\n",
        "                    beta[i] = (beta[i] + betamin) / 2;\n",
        "\n",
        "            # Recompute the values\n",
        "            (H, thisP) = Hbeta(Di, beta[i])\n",
        "            Hdiff = H - logU\n",
        "            tries = tries + 1\n",
        "\n",
        "        # Set the final row of P\n",
        "        P[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))] = thisP\n",
        "\n",
        "    # Return final P-matrix\n",
        "    sigma = np.mean(np.sqrt(1 / beta))\n",
        "    print(f'Mean value of sigma: {sigma:.3f}')\n",
        "    return P\n",
        "\n",
        "\n",
        "def pca(X = np.array([]), no_dims = 50):\n",
        "    \"\"\"Runs PCA on the NxD array X in order to reduce its dimensionality to no_dims dimensions.\"\"\"\n",
        "\n",
        "    #print(\"Preprocessing the data using PCA...\")\n",
        "    (n, d) = X.shape\n",
        "    X = X - np.tile(np.mean(X, 0), (n, 1))\n",
        "    (l, M) = np.linalg.eig(np.dot(X.T, X))\n",
        "    Y = np.dot(X, M[:,0:no_dims])\n",
        "    return Y\n",
        "\n",
        "\n",
        "def tsne(X = np.array([]), no_dims=2, initial_dims=50, perplexity=30.0):\n",
        "    \"\"\"\n",
        "    Runs t-SNE on the dataset in the NxD array X to reduce its dimensionality to no_dims dimensions.\n",
        "    The syntaxis of the function is Y = tsne.tsne(X, no_dims, perplexity), where X is an NxD NumPy array.\n",
        "    \"\"\"\n",
        "\n",
        "    # Check inputs\n",
        "    if isinstance(no_dims, float):\n",
        "        print(\"Error: array X should have type float.\")\n",
        "        return -1\n",
        "    if round(no_dims) != no_dims:\n",
        "        print(\"Error: number of dimensions should be an integer.\")\n",
        "        return -1\n",
        "\n",
        "    # Initialize variables\n",
        "    X = pca(X, initial_dims).real\n",
        "    (n, d) = X.shape\n",
        "    max_iter = 1000\n",
        "    initial_momentum = 0.5\n",
        "    final_momentum = 0.8\n",
        "    eta = 500\n",
        "    min_gain = 0.01\n",
        "    Y = np.random.randn(n, no_dims)\n",
        "    dY = np.zeros((n, no_dims))\n",
        "    iY = np.zeros((n, no_dims))\n",
        "    gains = np.ones((n, no_dims))\n",
        "\n",
        "    # Compute P-values\n",
        "    P = x2p(X, 1e-5, perplexity)\n",
        "    P = P + np.transpose(P)\n",
        "    P = P / np.sum(P)\n",
        "    P = P * 4   # early exaggeration\n",
        "    P = np.maximum(P, 1e-12)\n",
        "    #P = np.maximum(P, 1e-5)\n",
        "\n",
        "    interval = int(max_iter >> 2)\n",
        "    # Run iterations\n",
        "    for iter in range(max_iter):\n",
        "        # Compute pairwise affinities\n",
        "        sum_Y = np.sum(np.square(Y), 1)\n",
        "        num = 1 / (1 + np.add(np.add(-2 * np.dot(Y, Y.T), sum_Y).T, sum_Y))\n",
        "        num[range(n), range(n)] = 0\n",
        "        Q = num / np.sum(num)\n",
        "        Q = np.maximum(Q, 1e-12)\n",
        "        #Q = np.maximum(Q, 1e-5)\n",
        "\n",
        "        # Compute gradient\n",
        "        PQ = P - Q;\n",
        "        for i in range(n):\n",
        "            dY[i,:] = np.sum(np.tile(PQ[:,i] * num[:,i], (no_dims, 1)).T * (Y[i,:] - Y), 0)\n",
        "\n",
        "        # Perform the update\n",
        "        if iter < 20:\n",
        "            momentum = initial_momentum\n",
        "        else:\n",
        "            momentum = final_momentum\n",
        "        gains = (gains + 0.2) * ((dY > 0) != (iY > 0)) + (gains * 0.8) * ((dY > 0) == (iY > 0))\n",
        "        gains[gains < min_gain] = min_gain\n",
        "        iY = momentum * iY - eta * (gains * dY)\n",
        "        Y = Y + iY\n",
        "        Y = Y - np.tile(np.mean(Y, 0), (n, 1))\n",
        "\n",
        "        # Compute current value of cost function\n",
        "        #if (iter + 1) % 10 == 0:\n",
        "        #if (iter + 1) % interval == 0:\n",
        "        #    C = np.sum(P * np.log(P / Q))\n",
        "        #    print(f\"Iteration {(iter + 1):<5d}: error is {C:.3f}\")\n",
        "\n",
        "        # Stop lying about P-values\n",
        "        if iter == 100:\n",
        "            P = P / 4;\n",
        "\n",
        "    # Return solution\n",
        "    return Y;\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "# \tprint(\"Run Y = tsne.tsne(X, no_dims, perplexity) to perform t-SNE on your dataset.\")\n",
        "# \tprint(\"Running example on 2,500 MNIST digits...\")\n",
        "# \tX = np.loadtxt(\"mnist2500_X.txt\");\n",
        "# \tlabels = np.loadtxt(\"mnist2500_labels.txt\");\n",
        "# \tY = tsne(X, 2, 50, 20.0);\n",
        "# \tPlot.scatter(Y[:,0], Y[:,1], 20, labels);\n",
        "# \tPlot.show();\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NicK62d-Mija"
      },
      "source": [
        "tlpa_cats = list(set(tlpa_cat))\n",
        "tlpa_colors = [tlpa_cats.index(c) for c in tlpa_cat]\n",
        "\n",
        "def draw_tSNE_plot(data, \n",
        "                   colors=tlpa_colors,\n",
        "                   labels=tlpa_labels, \n",
        "                   fontsize=16, \n",
        "                   figsize=(16,16),\n",
        "                   xmax=None, xmin=None,\n",
        "                   ymax=None, ymin=None,\n",
        "                   save_figname=None,\n",
        "                   grid = True,\n",
        "                   auto_lim = True,\n",
        "                  ):\n",
        "    \"\"\"tSNE のプロットを描画する関数\n",
        "    \n",
        "    引数:\n",
        "    data: np.array[N,2]\n",
        "        tSNE の結果\n",
        "    colors: list[N] \n",
        "        各項目の色を指定する数字 N 個\n",
        "    labels: list[str]\n",
        "        散布図中に表示する項目名のリスト\n",
        "    figsize: タプル\n",
        "        縦横のサイズ。単位はインチ。だが昔と違ってディスプレイサイズがまちまちなので目安でしか無い\n",
        "    xmax, xmin, ymax, ymin: int\n",
        "        図の最大値と最小値を指定する。\n",
        "        指定しなければ自動計算する\n",
        "    save_figname: str\n",
        "        保存するファイル名 pdf ファイルとして保存するなら .pdf 拡張子をつける\n",
        "    grid: Boolean\n",
        "        図中にグリッドを表示するか否か。デフォルトは True\n",
        "    auto_lim: Boolean\n",
        "        最大値最小値を自動計算するか否か\n",
        "        xmax, xmin, ymax, ymin が指定されていれば自動的に False になる\n",
        "    \"\"\"\n",
        "\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    axe = fig.add_subplot(1,1,1)\n",
        "\n",
        "    if xmax == None: xmax = (X[:,0]).max(); auto_lim = False\n",
        "    if xmin == None: xmin = (X[:,0]).min(); auto_lim = False\n",
        "    if ymax == None: ymax = (X[:,1]).max(); auto_lim = False\n",
        "    if ymin == None: ymin = (X[:,1]).min(); auto_lim = False\n",
        "    if auto_lim: \n",
        "        axe.set_xlim(xmin, xmax); axe.set_ylim(ymin, ymax)\n",
        "\n",
        "    if grid:\n",
        "        axe.grid()\n",
        "\n",
        "    axe.scatter(data[:,0], data[:,1], 120, colors)\n",
        "    for i, label in enumerate(labels):\n",
        "        axe.annotate(label, (data[i,0], data[i,1]), fontsize=fontsize)\n",
        "\n",
        "    if save_figname != None:\n",
        "        plt.savefig(save_figname)\n",
        "        \n",
        "    return fig, axe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dvwf5cDXB3Nz"
      },
      "source": [
        "# seed = 0\n",
        "# np.random.seed(seed)\n",
        "# X = np.array([w2v[word] for word in tlpa_labels], dtype=np.float)\n",
        "# tlpa_cats = list(set(tlpa_cat))\n",
        "# tlpa_colors = [tlpa_cats.index(c) for c in tlpa_cat]\n",
        "# tlpa_results = tsne(X, perplexity=30.0)\n",
        "# f, axe = draw_tSNE_plot(tlpa_results, labels=tlpa_labels, colors=tlpa_colors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1VL4AfvweMs"
      },
      "source": [
        "# 大門先生のデータ，天ぷら ---> たくあん と言う意味性錯語を検証\n",
        "def compare_distances_tSNE_word2vec(t_word='天ぷら', r_word='たくあん', \n",
        "                                    tlpa_labels=tlpa_labels, \n",
        "                                    seed=0, \n",
        "                                    perplexity=30.0, \n",
        "                                    save_fig=False,\n",
        "                                    draw_fig=True\n",
        "                                   ):\n",
        "    \n",
        "    # TLPA の単語ベクトルを X に代入\n",
        "    X = np.array([w2v[word] for word in tlpa_labels], dtype=np.float)\n",
        "    r_vec = [w2v[r_word]]  # 反応語の単語ベクトルを取得し r_vec に代入\n",
        "    \n",
        "    X_ = np.concatenate((X, r_vec), axis=0)  # X と r_vec を併せて新しい X_ を作成する\n",
        "    # 上の X_ に合わせてラベルデータ tlpa_labels_ を作成\n",
        "    tlpa_labels_ = ['バス', '緑', '桜', 'のり巻き', '五重塔', 'コップ', 'ごぼう', '土踏まず', '風呂', 'ヒトデ', \\\n",
        "                    'ハム', '兎', 'ロープウエイ', '学校', 'ちりとり', '縁側', '歯', 'ネギ', 'あじさい', '灰色', \\\n",
        "                    '天井', '鍵', '肌色', 'ワニ', '電車', '顔', '松', 'ガードレール', '柿', 'ちまき', '信号', \\\n",
        "                    'すすき', 'じょうろ', 'コンセント', '天ぷら', '中指', 'ヨット', 'ピンク', 'ふくろう', 'みかん', \\\n",
        "                    '柱', '角砂糖', '犬', 'かご', 'バラ', '鍋', 'まぶた', 'くるみ', '黒', 'デパート', 'カーネーション', \\\n",
        "                    '城', '蟻', '豆腐', 'ドライバー', '紺', '階段', '戦車', '人参', '背中', '鏡餅', 'スプーン', \\\n",
        "                    '朝顔', '金', '足', 'ふすま', '蛇', 'レモン', '公園', '乳母車', '床', '藤', 'ピンセット', \\\n",
        "                    'トラック', '苺', '黄土色', '銭湯', 'ナマズ', 'そば', 'お腹', 'オレンジ', 'バター', '工場', \\\n",
        "                    '鳩', '電卓', '喉仏', 'チューリップ', '白菜', 'トラクター', '廊下', 'パトカー', '押入れ', \\\n",
        "                    '鉛筆', '目尻', '芋', '吊り橋', '赤', 'かき氷', '豹', 'サボテン', 'ピラミッド', 'サイ', '目', \\\n",
        "                    'ひまわり', 'はたき', '刺し身', '玄関', 'トマト', '黄緑', '三輪車', '鶏', 'つむじ', 'アスパラガス', \\\n",
        "                    'ドア', '銀色', 'すりこ木', 'ウイスキー', '梅', 'タクシー', '動物園', '床の間', '焦げ茶', 'ぶどう', \\\n",
        "                    '飴', '毛虫', 'アイロン', '寺', 'そり', 'ひょうたん', '首', '消しゴム', '頬', 'いちょう', '駅', \\\n",
        "                    'ギョウザ', '牛', 'びわ', '飛行機', '畳', '白', '竹', 'ペリカン', '紫', '手すり', '口', '大根', \\\n",
        "                    '風車', '鋏', '潜水艦', 'ステーキ', 'マッチ', '二階', '落花生', '御飯', '自転車', '歩道橋', '鯨', \\\n",
        "                    '茶色', '菖蒲', 'ふくらはぎ', '桃', 'たいやき', '道路', '靴べら', '水色', '壁', 'たんぽぽ', \\\n",
        "                    'いかだ', '山羊', '鼻', '海老', '台所', 'オートバイ', 'かぶ', '柳', 'しゃもじ', 'まんじゅう', \\\n",
        "                    'かかと', '薄紫', '家', 'おせち料理', '青', '傘', 'つくし', 'りんご', '馬車', '線路', \\\n",
        "                    'タツノオトシゴ', '耳', '便所', '蓮根', '猫', '黄色', 'へそ', '街灯', '障子', '酒', '船', \\\n",
        "                    '安全ピン', 'もみじ', r_word]\n",
        "    # 反応語を最後に入れたので，その語の色を 11 番目の色として設定\n",
        "    tlpa_colors_ = [8, 7, 5, 0, 2, 4, 9, 6, 3, 1, 0, 1, 8, 2, 4, 3, 6, 9, 5, 7, 3, 4, 7, 1, 8, 6, 5, 2, 9, 0, 2, 5, 4, 3, 0, 6, 8, 7, 1, 9, 3, 0, 1, 8, 5, 4, 6, 9, 7, 2, 5, 2, 1, 0, 4, 7, 3, 8, 9, 6, 0, 4, 5, 7, 6, 3, 1, 9, 2, 8, 3, 5, 4, 8, 9, 7, 2, 1, 0, 6, 7, 0, 2, 1, 4, 6, 5, 9, 8, 3, 8, 3, 4, 6, 9, 2, 7, 0, 1, 5, 2, 1, 6, 5, 4, 0, 3, 9, 7, 8, 1, 6, 9, 3, 7, 4, 0, 5, 8, 2, 3, 7, 9, 0, 1, 4, 2, 8, 5, 6, 4, 6, 5, 2, 0, 1, 9, 8, 3, 7, 5, 1, 7, 3, 6, 9, 2, 4, 8, 0, 4, 3, 9, 0, 8, 2, 1, 7, 5, 6, 9, 0, 2, 4, 7, 3, 5, 8, 1, 6, 1, 3, 8, 9, 5, 4, 0, 6, 7, 2, 0, 7, 4, 5, 9, 8, 2, 1, 6, 3, 9, 1, 7, 6, 2, 3, 0, 8, 4, 5, 10]\n",
        "\n",
        "    t_num = tlpa_labels_.index(t_word)\n",
        "    r_num = tlpa_labels_.index(r_word)\n",
        "    tlpa_colors_[t_num] = 10  # 図を見やすくするため，ターゲット語の色を表出語の色と同じ 11 番目の色に設定\n",
        "\n",
        "    np.random.seed(seed)  # 乱数の種を設定\n",
        "    tlpa_results_ = tsne(X_, perplexity=perplexity)  # tSNE の実行\n",
        "    if draw_fig:\n",
        "        f, axe = draw_tSNE_plot(tlpa_results_, labels=tlpa_labels_, colors=tlpa_colors_)\n",
        "    if save_fig:\n",
        "        save_fname = '2021_0825'+t_word+'_'+r_word+'.pdf'\n",
        "        plt.savefig(save_fname)\n",
        "    plt.show()\n",
        "    a = tlpa_results_[t_num]  # ターゲット語の tSNE 座標を取得して a に代入\n",
        "    b = tlpa_results_[r_num]  # 表出語の tSNE 座標を取得して b に代入\n",
        "    #print(f'{t_word}: {a} {r_word}: {b}')  # 結果を表示\n",
        "    tsne_dist = np.linalg.norm(a - b)      # ターゲット語と表出語のユークリッド距離を計算し tsne_dist に代入\n",
        "    w2v_dist = w2v.distance(t_word, r_word)\n",
        "    #print(f'{t_word} と {r_word} との tSNE 上での距離: {dist:.3f}',\n",
        "    #      f'word2vec 上での距離: {w2v_dist:.3f}')\n",
        "    return tsne_dist, w2v_dist\n",
        "\n",
        "\n",
        "\n",
        "# #大門先生のデータ，各リストの要素はタプルで，タプルの先頭が刺激語，2番目が反応\n",
        "# daimon_results = [ ('あじさい', 'フラワー'), ('ちまき','ふきのとう'), \n",
        "#                   ('天ぷら','たくあん'), ('角砂糖','ストロー'), \n",
        "#                   ('角砂糖', 'フォーク'), ('鍋','やかん'),\n",
        "#                   ('城','やぐら'), ('廊下','戸締り'), \n",
        "#                   ('安全ピン','ピンセット')  #これだけは形式性錯語\n",
        "#                  ]\n",
        "\n",
        "# for pair in daimon_results:\n",
        "#     tsne_dist, w2v_dist = compare_distances_tSNE_word2vec(pair[0], pair[1], save_fig=False, draw_fig=False)\n",
        "#     print(f'{pair[0]} と {pair[1]} との tSNE 上での距離: {tsne_dist:.3f}, w2v 上での距離(1-similarity):{w2v_dist:.3f}')\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcZQcdENDAVy"
      },
      "source": [
        "w_target = input('TLPA 検査項目 200 語のうち一語を入力してください')\n",
        "w_resp   = input('対応する産出された語を入力してください') \n",
        "tsne_dist, w2v_dist = compare_distances_tSNE_word2vec(w_target, w_resp, save_fig=False, draw_fig=False)\n",
        "print(f'{w_target} と {w_resp} との tSNE 上での距離: {tsne_dist:.3f}, w2v 上での距離(非類似度):{w2v_dist:.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}