{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/2015corona/blob/master/2023notebooks/2023_0602Transformer_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3339b396-d686-4587-8ebf-44a603f37c5c",
      "metadata": {
        "id": "3339b396-d686-4587-8ebf-44a603f37c5c"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "import torch\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "from IPython import get_ipython\n",
        "isColab =  'google.colab' in str(get_ipython())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7765dc43-eccd-40f8-bddf-ac60af4084c6",
      "metadata": {
        "id": "7765dc43-eccd-40f8-bddf-ac60af4084c6"
      },
      "source": [
        "# PyTorch による Transformer の実装\n",
        "\n",
        "このチュートリアルでは PyTorch を使用して基本的な Transformer モデルをゼロから構築する。\n",
        "Transformer モデルは Vaswani+ が論文 [Attention is All You Need](https://arxiv.org/abs/1706.03762) で導入したもので，機械翻訳やテキスト要約などの seq2seq 課題のために設計された深層学習アーキテクチャである。\n",
        "自己注意機構に基づいており，GPT や BERT など，多くの最先端の自然言語処理モデルの基盤となっている。\n",
        "\n",
        "Transformer モデルの作成においては以下の段階を踏む:\n",
        "\n",
        "1. 必要なライブラリやモジュールの輸入\n",
        "2. 基本的な構成要素を定義: マルチヘッド注意，位置ごとのフィードフォワードネットワーク，位置符号化器\n",
        "3. 符号化器と復号化器の層の定義\n",
        "4. 符号化器と復号化器の層を組み合わせて，完全な transformer モデルを実装\n",
        "5. サンプルデータの作成\n",
        "6. モデルの訓練\n",
        "\n",
        "以下，順を追って説明する。\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 必要なライブラリやモジュールの輸入\n"
      ],
      "metadata": {
        "id": "79LM98hA_k_y"
      },
      "id": "79LM98hA_k_y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7442f857-e304-4c93-9c02-62afe668e737",
      "metadata": {
        "id": "7442f857-e304-4c93-9c02-62afe668e737"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import math\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f92e416-9c9f-48da-a3f5-b9983cd9cb9b",
      "metadata": {
        "id": "3f92e416-9c9f-48da-a3f5-b9983cd9cb9b"
      },
      "source": [
        "## 2. Transformer モデルの基本的な構成要素の定義\n",
        "\n",
        "### 2.1. マルチヘッド注意\n",
        "\n",
        "マルチヘッド注意機構は，系列内の各対の位置間の注意を計算する。\n",
        "これは，入力系列の異なる側面を捉える複数の `注意ヘッド` で構成される。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a3cfacf-412b-4691-8aeb-899e1828a22f",
      "metadata": {
        "id": "2a3cfacf-412b-4691-8aeb-899e1828a22f"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    このコードは，入力パラメータと線形変換層でモジュールを初期化し，\n",
        "    注意得点を計算し，入力テンソルを複数のヘッドに再整形し，すべてのヘッドからの注意出力を結合する。\n",
        "    `forward()` はマルチヘッド自己注意を計算し，モデルが入力系列の別の面に注意を向けることを可能にする。\n",
        "    \"\"\"\n",
        "    def __init__(self, \n",
        "                 d_model:int,    # 各層の素子数\n",
        "                 num_heads:int   # ヘッド数，マルチヘッド注意の定義に必要\n",
        "                ):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model は num_heads で割り切れる数である必要がある\"\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "        \n",
        "        # クエリ行列\n",
        "        self.W_q = nn.Linear(in_features=d_model, out_features=d_model)\n",
        "\n",
        "        # キー行列\n",
        "        self.W_k = nn.Linear(in_features=d_model, out_features=d_model)\n",
        "\n",
        "        # バリュー行列\n",
        "        self.W_v = nn.Linear(in_features=d_model, out_features=d_model)\n",
        "\n",
        "        # 出力行列\n",
        "        self.W_o = nn.Linear(in_features=d_model, out_features=d_model)\n",
        "        \n",
        "    def scaled_dot_product_attention(self, \n",
        "                                     Q:torch.Tensor, \n",
        "                                     K:torch.Tensor, \n",
        "                                     V:torch.Tensor, \n",
        "                                     mask=None):\n",
        "        \"\"\"規格化したドット積注意\"\"\"\n",
        "\n",
        "        # クエリ行列とキー行列をかけて注意得点を算出，K.transpose(-2,-1) は行列の転置\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "\n",
        "        if mask is not None:  # マスクをかける\n",
        "            attn_scores = attn_scores.masked_fill(mask==0, -1e9)\n",
        "\n",
        "        # 注意得点にソフトマックスをかける\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "\n",
        "        # ソフトマックスにかけた注意得点に対して，バリュー行列をかけて出力を計算\n",
        "        output = torch.matmul(attn_probs, V)\n",
        "        return output\n",
        "        \n",
        "    def split_heads(self, \n",
        "                    x:torch.Tensor):\n",
        "        \"\"\"注意のヘッドを分割\"\"\"\n",
        "        # 入力データ x の次元から，バッチサイズ，系列長，モデルの素子数を算出\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "\n",
        "        # 入力データを分割して返す\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        \n",
        "    def combine_heads(self, \n",
        "                      x:torch.Tensor):\n",
        "        \"\"\"分割したヘッドを統合\"\"\"\n",
        "        batch_size, _, seq_length, d_k = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
        "        \n",
        "    def forward(self, \n",
        "                Q:torch.Tensor, \n",
        "                K:torch.Tensor, \n",
        "                V:torch.Tensor, mask=None):\n",
        "        \"\"\"マルチヘッド注意の順向処理\"\"\"\n",
        "        Q = self.split_heads(self.W_q(Q))\n",
        "        K = self.split_heads(self.W_k(K))\n",
        "        V = self.split_heads(self.W_v(V))\n",
        "        \n",
        "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "        output = self.W_o(self.combine_heads(attn_output))\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d864370-728d-487c-bcb2-a0b70a183e92",
      "metadata": {
        "id": "6d864370-728d-487c-bcb2-a0b70a183e92"
      },
      "source": [
        "\n",
        "### 2.2 位置ごとのフィードフォワードネットワーク <!--Position-wise_FeedForward_Networks-->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c7dfe58-1ca1-4de8-9e34-99f4de6d5a4a",
      "metadata": {
        "id": "7c7dfe58-1ca1-4de8-9e34-99f4de6d5a4a"
      },
      "outputs": [],
      "source": [
        "class PositionWiseFeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    PyTorch の `nn.Module` を拡張した，位置毎のフィードフォワードネットワークの実装\n",
        "    このクラスは，2 つの線形変換層と整流線形化 (ReLU) 活性化関数で初期化される。\n",
        "    `forward()` は，これらの変換と活性化関数を順次適用して出力を計算する。\n",
        "    この処理により，モデルは入力要素の位置を考慮しながら予測を行うことができる。\n",
        "    \"\"\"\n",
        "    def __init__(self, \n",
        "                 d_model:int, \n",
        "                 d_ff:int):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_features=d_model, out_features=d_ff)\n",
        "        self.fc2 = nn.Linear(in_features=d_ff, out_features=d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ab64b9b-d7af-4ae8-8d08-d7b1363ddd89",
      "metadata": {
        "id": "0ab64b9b-d7af-4ae8-8d08-d7b1363ddd89"
      },
      "source": [
        "### 2.3 位置符号化器 Positional Encoding\n",
        "\n",
        "位置符号化は，入力系列の各トークンの位置情報を挿入するために使用される。\n",
        "異なる周波数の正弦波関数と余弦波関数を使用して位置情報を生成する。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad593e9e-a8ad-436f-9784-00a5f2c50275",
      "metadata": {
        "id": "ad593e9e-a8ad-436f-9784-00a5f2c50275"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    入力パラメータ `d_model` と `max_seq_length` で初期化し，位置符号化器の値を格納するテンソルを作成する。\n",
        "    このクラスは，スケール因子 `div_term` に基づいて，偶数インデックスと奇数インデックスの正弦波と余弦波の値をそれぞれ計算する。\n",
        "    `forward()` は，格納された位置符号化値を入力テンソルに追加することで位置符号化を計算し，モデルが入力配列の位置情報を捕捉できるようにする。\n",
        "\n",
        "    位置符号化では，位置に応じて正弦波が加算される。\n",
        "    周波数とオフセットは，各次元で異なる。\n",
        "    \"\"\"\n",
        "    def __init__(self, \n",
        "                 d_model:int, \n",
        "                 max_seq_length:int):\n",
        "        super().__init__()\n",
        "        \n",
        "        pe = torch.zeros(max_seq_length, d_model)\n",
        "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
        "        \n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        \n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59c4c16d-b440-4ba3-8365-992003257671",
      "metadata": {
        "id": "59c4c16d-b440-4ba3-8365-992003257671"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib\n",
        "    \n",
        "plt.figure(figsize=(15, 5))\n",
        "pe = PositionalEncoding(d_model=20, max_seq_length=500)\n",
        "y = pe.forward(Variable(torch.zeros(1, 100, 20)))\n",
        "plt.plot(np.arange(100), y[0, :, 4:8].data.numpy())\n",
        "plt.legend([f\"次元 {p}\" for p in [4,5,6,7]])\n",
        "plt.title('位置符号化器の各位置に対応する出力\\n位置符号化の下では，位置に対応した正弦波が追加される。 この正弦波の周波数とオフセットは，各次元で異なる。')\n",
        "plt.xlabel('位置')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "079669ae-5a93-4728-bf25-e706fa3688e9",
      "metadata": {
        "id": "079669ae-5a93-4728-bf25-e706fa3688e9"
      },
      "source": [
        "## 3. 符号化器層 Encoder Layer\n",
        "\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:552/format:webp/0*bPKV4ekQr9ZjYkWJ.png\" width=\"18%\"><br/>\n",
        "図 Transformer ネットワークの符号化器部分\n",
        "</center>\n",
        "\n",
        "符号化器層は，マルチヘッド注意層，位置ごとのフィードフォワード層，2 つの層正規化層で構成される。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d11c510b-f0a9-4cc5-993e-bae43b5051a9",
      "metadata": {
        "id": "d11c510b-f0a9-4cc5-993e-bae43b5051a9"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    入力パラメータと，`MultiHeadAttention` モジュール，\n",
        "    `PositionWiseFeedForward` モジュール，\n",
        "    2 つの層正規化モジュール，ドロップアウト層などの成分で初期化。\n",
        "    `forward()` は，自己注意を適用して符号化層の出力を計算し，注意出力を入力テンソルに加え，その結果を正規化する。\n",
        "    次に，位置ごとのフィードフォワード出力を計算し，正規化された自己注意出力と結合し，最終結果を正規化してから処理されたテンソルを返す。\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x, mask):\n",
        "        attn_output = self.self_attn(x, x, x, mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b99f6603-f839-480b-b686-3c8e77d3afc8",
      "metadata": {
        "id": "b99f6603-f839-480b-b686-3c8e77d3afc8"
      },
      "source": [
        "## 4. 復号化器層 Decoder Layer\n",
        "\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:552/format:webp/0*SPZgT4k8GQi37H__.png\" width=\"18%\"><br/>\n",
        "図 4. Transformer ネットワークの復号化器部分    \n",
        "<!-- Figure 4. The Decoder part of the Transformer network (Souce: Image from the original paper) -->\n",
        "</center>\n",
        "\n",
        "復号化器層は，2 つのマルチヘッド注意層，位置ごとのフィードフォワード層，3 つの層正規化層で構成される。\n",
        "<!-- A Decoder layer consists of two Multi-Head Attention layers, a Position-wise Feed-Forward layer, and three Layer Normalization layers. -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b328fed3-19ce-4713-8a57-35c05d579f01",
      "metadata": {
        "id": "b328fed3-19ce-4713-8a57-35c05d579f01"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    入力パラメータと，マスクされた自己注意と交差注意のためのマルチヘッド注意モジュール，\n",
        "    位置ごとのフィードフォワードモジュール，3  層の正規化モジュール，およびドロップアウト層などの成分で初期化\n",
        "\n",
        "    `forward()`は，以下のステップを実行することで，復号化器層の出力を計算する:\n",
        "    1. マスクされた自己注意出力を計算し，入力テンソルに加算した後，ドロップアウトと層正規化を行う。\n",
        "    2. 復号化器出力と符号化器出力の間の交差注意出力を計算し，正規化されたマスクされた自己注意出力に加え，ドロップアウトと層正規化を行う。\n",
        "    3. 位置ごとのフィードフォワード出力を計算し，正規化された交差注意出力に加え，ドロップアウトと層正規化を行う。\n",
        "    4. 処理されたテンソルを返す。\n",
        "\n",
        "    これらにより，復号化は入力と符号化出力に基づいて標的系列を生成する\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
        "        x = self.norm2(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm3(x + self.dropout(ff_output))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72b302eb-47a8-4785-8c37-d4d493342c73",
      "metadata": {
        "id": "72b302eb-47a8-4785-8c37-d4d493342c73"
      },
      "source": [
        "## 5. 符号化器と復号化器の層を組み合わせて，Transformer モデルの実装\n",
        "\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1090/format:webp/0*ljYs7oOlKC71SzSr.png\" width=\"33%\"><br/>\n",
        "Figure 5. The Transformer Network (Source: Image from the original paper)\n",
        "</center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f409dfb-3531-40c9-bcb1-13fcbc1ee405",
      "metadata": {
        "id": "7f409dfb-3531-40c9-bcb1-13fcbc1ee405"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    上で定義したモジュールを組み合わせて，Transformer モデルを定義\n",
        "    初期化の際 Transformer モジュールは入力パラメータを設定し，ソース系列とターゲット系列用の埋め込み層，\n",
        "    PositionalEncoding モジュール，スタック層を定義している。\n",
        "    EncoderLayer と DecoderLayer モジュール，復号化器出力を射影する線形層，ドロップアウト層など様々な成分を初期化。\n",
        "\n",
        "    `generate_mask()` は，パディングトークンを無視し，復号化器が将来のトークンに注目しないように，ソースとターゲット系列に二値化マスクを作成する。\n",
        "\n",
        "    `forward()`ドは，以下のステップで Transformer モデルの出力を計算する：\n",
        "    \n",
        "    1. `generate_mask()` でソースマスクとターゲットマスクを生成\n",
        "    2. ソースとターゲットの埋め込みを計算し，位置符号化とドロップアウトを適用\n",
        "    3. ソース系列を符号化層で処理し enc_output テンソルを更新\n",
        "    4. 符号化出力とマスクを用いて ターゲット系列を復号化器層で処理し，`dec_output` テンソルを更新\n",
        "    5. 復号化器出力に線形射影層を適用し，出力ロジットを算出\n",
        "\n",
        "    これらにより Transformer モデルは，成分の組み合わせ機能に基づいて，入力系列を処理し，出力系列を生成する\n",
        "    \"\"\"\n",
        "    def __init__(self, \n",
        "                 src_vocab_size, \n",
        "                 tgt_vocab_size, \n",
        "                 d_model, \n",
        "                 num_heads, \n",
        "                 num_layers, \n",
        "                 d_ff, \n",
        "                 max_seq_length, \n",
        "                 dropout):\n",
        "        super().__init__()\n",
        "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
        "\n",
        "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def generate_mask(self, src, tgt):\n",
        "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
        "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
        "        seq_length = tgt.size(1)\n",
        "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
        "        tgt_mask = tgt_mask & nopeak_mask\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
        "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
        "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
        "\n",
        "        enc_output = src_embedded\n",
        "        for enc_layer in self.encoder_layers:\n",
        "            enc_output = enc_layer(enc_output, src_mask)\n",
        "\n",
        "        dec_output = tgt_embedded\n",
        "        for dec_layer in self.decoder_layers:\n",
        "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        output = self.fc(dec_output)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7f6b1ba-d047-452e-a3e8-c51ec66168bf",
      "metadata": {
        "id": "f7f6b1ba-d047-452e-a3e8-c51ec66168bf"
      },
      "source": [
        "## 6. サンプルデータの準備\n",
        "\n",
        "この例では，デモ用におもちゃのデータセットを作成する。\n",
        "実際には，より大きなデータセットを使用し，テキストを前処理し，ソース言語とターゲット言語の語彙写像を作成することになる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49edeeb9-d348-41b5-9418-5ede1e752699",
      "metadata": {
        "id": "49edeeb9-d348-41b5-9418-5ede1e752699"
      },
      "outputs": [],
      "source": [
        "src_vocab_size = 5000\n",
        "tgt_vocab_size = 5000\n",
        "d_model = 512\n",
        "num_heads = 8\n",
        "num_layers = 6\n",
        "d_ff = 2048\n",
        "max_seq_length = 100\n",
        "dropout = 0.1\n",
        "\n",
        "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)\n",
        "\n",
        "# サンプルデータの生成\n",
        "src_data = torch.randint(1, src_vocab_size, (64, max_seq_length))  # (batch_size, seq_length)\n",
        "tgt_data = torch.randint(1, tgt_vocab_size, (64, max_seq_length))  # (batch_size, seq_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e8987cd-e182-48ff-8c6d-1c2ed6d6f877",
      "metadata": {
        "id": "6e8987cd-e182-48ff-8c6d-1c2ed6d6f877"
      },
      "source": [
        "## 7. モデルの訓練\n",
        "\n",
        "では，サンプルデータを使ってモデルを訓練してみよう。\n",
        "実際には，もっと大きなデータセットを使って，訓練セットと検証セットに分けることになる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7adea9b6-a8b1-4194-9b93-ee8bc9658e99",
      "metadata": {
        "id": "7adea9b6-a8b1-4194-9b93-ee8bc9658e99"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "transformer.train()\n",
        "\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    output = transformer(src_data, tgt_data[:, :-1])\n",
        "    loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_data[:, 1:].contiguous().view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch: {epoch+1:3d}, Loss: {loss.item():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75a0e472-0b04-45fe-9934-9908d3e5ae01",
      "metadata": {
        "id": "75a0e472-0b04-45fe-9934-9908d3e5ae01"
      },
      "source": [
        "このコードにより Pytorch でゼロから簡単な Transformer を構築することが可能である。\n",
        "\n",
        "すべての大規模言語モデル (LLM) は，この Transformer 符号器または復号化器ブロックを学習に使用している。\n",
        "したがって，すべてを開始したネットワークを理解することは非常に重要である。\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}