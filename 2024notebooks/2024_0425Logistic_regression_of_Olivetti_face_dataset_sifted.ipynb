{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/2015corona/blob/master/2024notebooks/2024_0425Logistic_regression_of_Olivetti_face_dataset_sifted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# オリベッティ顔データベースを用いた顔認識\n",
        "\n",
        "* Date: 2024_0425\n",
        "* Author: 浅川 伸一 educ0233@komazawa-u.ac.jp\n",
        "\n",
        "* 自身の Google Drive にコピーした上で実行してください。"
      ],
      "metadata": {
        "id": "45RUJn8t1-x3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5gCgRcu1XCU"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib\n",
        "\n",
        "data = fetch_olivetti_faces()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "import IPython\n",
        "isColab = 'google.colab' in str(IPython.get_ipython())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "\n",
        "data = fetch_olivetti_faces()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "print(f\"目標とするクラス(画像中の人物の数) :{np.unique(y)}\")\n"
      ],
      "metadata": {
        "id": "G_nYg0nr1j33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nrows = 40   # nrows 人分のデータを表示\n",
        "#nrows = 4\n",
        "ncols = 10\n",
        "fig, fig_axes = plt.subplots(ncols=ncols, nrows=nrows, figsize=(ncols * 1.4, nrows * 1.4), constrained_layout=True)\n",
        "# constrained_layout は subplot や 凡例やカラーバーなどの装飾を自動的に調整して，\n",
        "# ユーザが要求する論理的なレイアウトをできるだけ維持しながら， 図ウィンドウに収まるようにします。\n",
        "\n",
        "for i in range(nrows):\n",
        "    for j in range(ncols):\n",
        "        x = i * 10 + j\n",
        "        fig_axes[i][j].imshow(X[x].reshape(64,64), cmap='gray')\n",
        "        fig_axes[i][j].axis('off')\n",
        "        fig_axes[i][j].set_title(f'num:{x}, ID:{y[x]}')"
      ],
      "metadata": {
        "id": "m19cNrx61zsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num = 39\n",
        "plt.imshow(X_sifted[num].reshape(64,64), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(X[num].reshape(64,64), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gci8WKYXoUGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 機械学習手法による顔認識\n",
        "\n",
        "## データの分割，訓練データとテストデータ\n",
        "\n",
        "データを 2 分割して，訓練データセットとテストデータセットに分割します。\n",
        "分割した訓練データセットでモデルのパラメータを学習し，しかる後に，テストデータセットで，その汎化性能を評価します。\n",
        "このとき，テストデータセットでの性能が高いモデルが良いモデルということになります。\n",
        "\n",
        "オリベッティ顔データセットには， 各被験者の 10 枚の顔画像が含まれています。\n",
        "このうち，例えば 90% を訓練データとし，10% をテストデータとして使用することを考えます。\n",
        "各顔データの訓練画像とテスト画像の数が同じになるように stratify 機能を使用してます。\n",
        "したがって，各被験者には 9 枚の訓練用画像と 1 枚のテスト用画像が用意されることになります。\n",
        "訓練データとテストデータの割合は split_ratio 変更することができます。\n"
      ],
      "metadata": {
        "id": "zlUVOrsL18sO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "import seaborn as sns  # ヒートマップ描画のために使用します\n",
        "\n",
        "#from sklearn.decomposition import PCA\n",
        "#from sklearn.svm import SVC\n",
        "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "# split_ratio = 0.1 としているので，訓練データ対テストデータが 9:1 になります\n",
        "split_ratio = 0.1\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=split_ratio, stratify=y, random_state=42)\n",
        "print(f'X_train 訓練画像のサイズ: {X_train.shape}')\n",
        "print(f'y_train 教師信号データのサイズ: {y_train.shape}')"
      ],
      "metadata": {
        "id": "tw6_ylJg13eH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ロジスティック回帰による予測"
      ],
      "metadata": {
        "id": "-T3_4VCA2JaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'max_iter':10 ** 3,\n",
        "          'C':1e3,\n",
        "          'penalty':'l2'}\n",
        "\n",
        "model = LogisticRegression(**params)\n",
        "model.fit(X_train, y_train)    # 訓練データを用いて線形判別分析モデルを訓練\n",
        "y_hat = model.predict(X_test)  # テストデータを使って予測を行い結果を y_hat に格納\n",
        "print(f\"ロジスティック回帰を用いた分類精度: {metrics.accuracy_score(y_test, y_hat):.3f}\")\n",
        "\n",
        "# 混同行列の表示\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(metrics.confusion_matrix(y_test, y_hat))"
      ],
      "metadata": {
        "id": "qEyj3n3_2HES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ロジスティック回帰の問題点\n",
        "\n",
        "データを右にシフトすると，いままでのパラメータがおかしくなる。\n",
        "このことを確かめてみましょう。"
      ],
      "metadata": {
        "id": "5JExar0H_9UD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sift = 3\n",
        "X_sifted = X.copy()\n",
        "for (x0, y0) in zip(X, X_sifted):\n",
        "    _x = x0.reshape(64,64)\n",
        "    _y = y0.reshape(64,64)\n",
        "    for  (__x, __y) in zip(_x, _y):\n",
        "        #print(__x.shape, __y.shape)\n",
        "        __y[:-sift] = __x[sift:]\n",
        "        __y[-sift:] = __x[:sift]\n",
        "\n",
        "y_hat_sifted = model.predict(X_sifted)\n",
        "#print(y_hat_sifted)"
      ],
      "metadata": {
        "id": "KaDarLyblq4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_hat)\n",
        "print(y_test)\n",
        "\n",
        "y_all = model.predict(X)\n",
        "print(y_all)\n",
        "print(y_hat_sifted)\n",
        "\n",
        "hit = (np.array(y_all == y_hat_sifted) * 1).sum()\n",
        "print(f'正解率: {hit/y_all.shape[0] * 100:.3f}%',\n",
        "      f' 正答数:{hit}',\n",
        "      f' 総データ数:{X.shape[0]}'\n",
        "      )"
      ],
      "metadata": {
        "id": "QBcFWiFXtJnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(metrics.confusion_matrix(y, y_hat_sifted))"
      ],
      "metadata": {
        "id": "SyQstp2jta5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "#sns.heatmap(metrics.confusion_matrix(y_test, y_hat))\n",
        "metrics.confusion_matrix(y, y_hat_sifted).shape"
      ],
      "metadata": {
        "id": "UGcNdOq9ynnx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}